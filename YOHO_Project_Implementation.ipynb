{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iB1i1GWBHMtA"
      },
      "source": [
        "# Initial Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ADDXE3rEV7zR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJjOWmynluge"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "import glob\n",
        "import csv\n",
        "import random\n",
        "from subprocess import Popen, PIPE\n",
        "from keras import regularizers\n",
        "from os.path import dirname\n",
        "import os\n",
        "import soundfile as sf\n",
        "!sudo apt-get install sox\n",
        "import math\n",
        "import numpy as np\n",
        "import librosa\n",
        "import shutil\n",
        "import pickle\n",
        "import re\n",
        "import tensorflow as tf\n",
        "!git clone https://github.com/DemisEom/SpecAugment.git\n",
        "!pip install /content/SpecAugment/ --quiet\n",
        "!pip install tensorflow-addons --quiet\n",
        "!pip install sed_eval --quiet\n",
        "import keras\n",
        "from SpecAugment import spec_augment_tensorflow\n",
        "import sed_eval\n",
        "import dcase_util\n",
        "from keras import regularizers\n",
        "from keras.regularizers import l2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Dataset"
      ],
      "metadata": {
        "id": "oplts-YdlJeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "import gdown\n",
        "\n",
        "output1 = \"/content/new-dataset/test_data1.zip\"\n",
        "gdown.download(id='17PvyXLEkpIgBLxRkuTIk25MGL3uM3kS1', output=output1, quiet=False)\n",
        "\n",
        "output2= \"/content/new-dataset/test_data2.zip\"\n",
        "gdown.download(id='14abMPBH3EVmcU-3jPD4jWEpa4pQ38OY9', output=output2, quiet=False)\n",
        "\n",
        "output3 = \"/content/new-dataset/test_data3.zip\"\n",
        "gdown.download(id='1TU4CoJuFy40-zJopo3R4U-YgZFKFrtxB', output=output3, quiet=False)\n",
        "\n",
        "output4 = \"/content/new-dataset/test_data4.zip\"\n",
        "gdown.download(id='1E5595RX2NwpuckXvl2o1V_dm9Ja58arF', output=output4, quiet=False)\n",
        "\n",
        "output5 = \"/content/new-dataset/test_data5.zip\"\n",
        "gdown.download(id='16VJhkCV2-ILcHxiF8a2ygEiHxXyF9RtM', output=output5, quiet=False)\n",
        "\n",
        "output6 = \"/content/new-dataset/test_data6.zip\"\n",
        "gdown.download(id='1kZyXyZVTHnSTg-gdrlf91V5ioYMr50Mp', output=output6, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "id": "NRQ9DlXiWdYi",
        "outputId": "3d0e523d-0bd9-485c-ec86-1f8b2f3a209c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.9/dist-packages (4.6.6)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.9/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from gdown) (3.10.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->gdown) (2.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17PvyXLEkpIgBLxRkuTIk25MGL3uM3kS1\n",
            "To: /content/new-dataset/test_data1.zip\n",
            "100%|██████████| 1.38G/1.38G [00:04<00:00, 300MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=14abMPBH3EVmcU-3jPD4jWEpa4pQ38OY9\n",
            "To: /content/new-dataset/test_data2.zip\n",
            "100%|██████████| 1.38G/1.38G [00:09<00:00, 149MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1TU4CoJuFy40-zJopo3R4U-YgZFKFrtxB\n",
            "To: /content/new-dataset/test_data3.zip\n",
            "100%|██████████| 1.34G/1.34G [00:08<00:00, 164MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1E5595RX2NwpuckXvl2o1V_dm9Ja58arF\n",
            "To: /content/new-dataset/test_data4.zip\n",
            "100%|██████████| 1.32G/1.32G [00:08<00:00, 158MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16VJhkCV2-ILcHxiF8a2ygEiHxXyF9RtM\n",
            "To: /content/new-dataset/test_data5.zip\n",
            "100%|██████████| 1.29G/1.29G [00:08<00:00, 144MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1kZyXyZVTHnSTg-gdrlf91V5ioYMr50Mp\n",
            "To: /content/new-dataset/test_data6.zip\n",
            "100%|██████████| 792M/792M [00:05<00:00, 142MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/new-dataset/test_data6.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_p7z3-QHotX"
      },
      "source": [
        "#Unzip all The data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4af7CjopKs0E"
      },
      "outputs": [],
      "source": [
        "def unzip_data(download_path, extract_path):\n",
        "\n",
        "  # create glob\n",
        "  final_glob = glob.glob(f\"{download_path}*.zip\")\n",
        "\n",
        "  for zip_name in final_glob:\n",
        "    with ZipFile(zip_name, 'r') as zip:\n",
        "      zip.extractall(extract_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLu4m-Q1Hnd0"
      },
      "outputs": [],
      "source": [
        "download_test_path = '/content/new-dataset/'\n",
        "extract_test_path = '/content/extracted-data'\n",
        "\n",
        "unzip_data(download_test_path, extract_test_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkRc04QOHwA3"
      },
      "source": [
        "# Extract Annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v36BZwiSDZg1"
      },
      "outputs": [],
      "source": [
        "def convert_annotations_to_events(filename): #read_annotations\n",
        "    events = []\n",
        "    with open(filename, 'r') as csvfile:\n",
        "        spamreader = csv.reader(csvfile, delimiter='\\t', quotechar='|')\n",
        "        for row in spamreader:\n",
        "            row.append(row[0])\n",
        "            row.pop(0)\n",
        "            row[1] = str((float(row[1])/1000))\n",
        "            row[0] = str((float(row[0])/1000))\n",
        "            events.append(row)\n",
        "    return events\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6CZDBeoDaPy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ff7ab13-c394-499d-becd-a94bda7b2144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['0.0', '8.027', 'footsteps'], ['8.027', '10.922', 'rainforest'], ['10.922', '16.762', 'car'], ['16.762', '25.854', 'footsteps'], ['25.854', '34.946', 'footsteps'], ['34.946', '38.773', 'crowds'], ['38.773', '48.773', 'aircraft'], ['48.773', '58.633', 'car'], ['58.633', '68.084', 'rainforest'], ['68.084', '75.751', 'aircraft'], ['75.751', '80.37', 'clocks'], ['80.37', '83.271', 'car']]\n"
          ]
        }
      ],
      "source": [
        "events = convert_annotations_to_events(\"/content/extracted-data/outputs/0.txt\")\n",
        "print(events)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess Audio "
      ],
      "metadata": {
        "id": "GJIKX8zVlfDX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcjhqP6-Mbuj"
      },
      "outputs": [],
      "source": [
        "audio_files = glob.glob(\"/content/extracted-data/outputs/*.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwG5VpfZUeeV"
      },
      "outputs": [],
      "source": [
        "os.makedirs(dirname(audio_files[0]).replace(\"outputs\", \"outputs-mono\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Flli3LPbTAEK"
      },
      "outputs": [],
      "source": [
        "for sound in audio_files:\n",
        "  temp_file = sound.replace(\"outputs\", \"outputs-mono\")\n",
        "  command = command = \"sox \" + sound + \" \" + temp_file + \" channels 1\"\n",
        "  p = Popen(command, stdin=PIPE, stdout=PIPE, stderr=PIPE, shell=True)\n",
        "  output, err = p.communicate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dY_Ri78WFR_"
      },
      "outputs": [],
      "source": [
        "audio_files_mono = glob.glob(\"/content/extracted-data/outputs-mono/*.wav\")\n",
        "random.shuffle(audio_files_mono)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VElzHF_ss3T1"
      },
      "source": [
        "# Split into folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gk-V6K0SCNt4",
        "outputId": "c8d9a784-7414-407f-f820-5e59764f30f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n"
          ]
        }
      ],
      "source": [
        "fold1_train_files = []\n",
        "fold1_val_files = []\n",
        "fold1_test_files = []\n",
        "print(len(audio_files_mono))\n",
        "audio_files_mono = audio_files_mono[:100]\n",
        "i = 0\n",
        "for f in audio_files_mono:\n",
        "  if i < 70:\n",
        "    fold1_train_files.append(f)\n",
        "  elif i < 90:\n",
        "    fold1_val_files.append(f)\n",
        "  else:\n",
        "    fold1_test_files.append(f)\n",
        "  i+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct Dataset"
      ],
      "metadata": {
        "id": "BRRabjwJl9bs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUElUf__xD3M"
      },
      "outputs": [],
      "source": [
        "def construct_examples(audio_path, win_len = 2.56, hop_len = 1.0, sr = 44100.0):\n",
        "  # here win_len is the window_length and hop_len is the hop_length between the examples.\n",
        "  # sr is the sampling rate\n",
        "\n",
        "  window_length_t = win_len\n",
        "  hop_length_t = hop_len\n",
        "\n",
        "  window_length = int(sr*window_length_t)\n",
        "  hop_length = int(sr*hop_length_t)\n",
        "\n",
        "  audio, sr = sf.read(audio_path)\n",
        "\n",
        "  # handle padding\n",
        "  if audio.shape[0] < window_length:\n",
        "    audio_padded = np.zeros((window_length, ))\n",
        "    audio_padded[0:audio.shape[0]] = audio \n",
        "\n",
        "  else:\n",
        "    no_of_hops = math.ceil((audio.shape[0] - window_length) / hop_length)\n",
        "    audio_padded = np.zeros((int(window_length + hop_length*no_of_hops), ))\n",
        "    audio_padded[0:audio.shape[0]] = audio  \n",
        "\n",
        "  audio_example = [audio_padded[i - window_length : i] for i in range(window_length, audio_padded.shape[0]+1, hop_length)]\n",
        "  win_ranges = [((i - window_length)/sr, i/sr) for i in range(window_length, audio_padded.shape[0]+1, hop_length)]\n",
        "\n",
        "  return audio_example, win_ranges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LScHoJOTkc6"
      },
      "outputs": [],
      "source": [
        "def construct_labels(annotation_path, win_start, win_end, win_len):\n",
        "  # takes the annotation_path, window_start, window_end and window_length\n",
        "  events = convert_annotations_to_events(annotation_path)\n",
        "\n",
        "  annotation_vals = [[float(e[0]), float(e[1]), e[2]] for e in events]\n",
        "\n",
        "  curr_annotation = []\n",
        "\n",
        "  for annotation in annotation_vals:\n",
        "    if annotation[1] > win_start and annotation[0] <= win_end: \n",
        "      curr_start = max(annotation[0] - win_start, 0.0)\n",
        "      curr_end = min(annotation[1] - win_start, win_len)\n",
        "      curr_annotation.append([curr_start, curr_end, annotation[2]])    \n",
        "\n",
        "  # get current class set from annotations\n",
        "  class_set = set([c[2] for c in curr_annotation])\n",
        "  class_wise_events = {}\n",
        "\n",
        "  for c in list(class_set):\n",
        "    class_wise_events[c] = []\n",
        "\n",
        "\n",
        "  for c in curr_annotation:\n",
        "    class_wise_events[c[2]].append(c)\n",
        "    \n",
        "  max_event_silence = 0.0\n",
        "  all_events = []\n",
        "\n",
        "  for k in list(class_wise_events.keys()):\n",
        "    curr_events = class_wise_events[k]\n",
        "    count = 0\n",
        "\n",
        "    while count < len(curr_events) - 1:\n",
        "      if (curr_events[count][1] >= curr_events[count + 1][0]) or (curr_events[count + 1][0] - curr_events[count][1] <= max_event_silence):\n",
        "        curr_events[count][1] = max(curr_events[count + 1][1], curr_events[count][1])\n",
        "        del curr_events[count + 1]\n",
        "      else:\n",
        "        count += 1\n",
        "\n",
        "    all_events += curr_events\n",
        "\n",
        "  for i in range(len(all_events)):\n",
        "    # round all the values so that they are not arbitarily long\n",
        "    all_events[i][0] = round(all_events[i][0], 3)\n",
        "    all_events[i][1] = round(all_events[i][1], 3)\n",
        "\n",
        "  all_events.sort(key=lambda x: x[0])\n",
        "\n",
        "  return all_events"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b32KeTkwsLEk"
      },
      "outputs": [],
      "source": [
        "def get_universal_labels(events, class_dict, ex_length = 10.0, no_of_div = 32):\n",
        "  # returns all labels from events\n",
        "  win_length = ex_length/no_of_div\n",
        "  labels = np.zeros((no_of_div, len(class_dict.keys()) * 3))\n",
        "  \n",
        "  for e in events:\n",
        "\n",
        "    start_time = float(e[0])\n",
        "    stop_time = float(e[1])\n",
        "\n",
        "    # to prevent edge case issues\n",
        "    if (float(e[0]) == 2.56):\n",
        "      start_time = float(e[0] - 0.00001)\n",
        "    if (float(e[1] == 2.56)):\n",
        "      stop_time = float(e[1]- 0.000001)\n",
        "     \n",
        "\n",
        "    start_bin = int(start_time // win_length)\n",
        "    stop_bin = int(stop_time // win_length)\n",
        "\n",
        "    start_time_2 = start_time - start_bin * win_length\n",
        "    stop_time_2 = stop_time - stop_bin * win_length\n",
        "\n",
        "    n_bins = stop_bin - start_bin\n",
        "\n",
        "    if n_bins == 0:\n",
        "      labels[start_bin, class_dict[e[2]] * 3:class_dict[e[2]] * 3 + 3] = [1, start_time_2, stop_time_2]    \n",
        "\n",
        "    elif n_bins == 1:\n",
        "      labels[start_bin, class_dict[e[2]] * 3:class_dict[e[2]] * 3 + 3] = [1, start_time_2, win_length]\n",
        "\n",
        "      if stop_time_2 > 0.0:\n",
        "        labels[stop_bin, class_dict[e[2]] * 3:class_dict[e[2]] * 3 + 3] = [1, 0.0, stop_time_2]\n",
        "\n",
        "    elif n_bins > 1:\n",
        "      labels[start_bin, class_dict[e[2]] * 3:class_dict[e[2]] * 3 + 3] = [1, start_time_2, win_length]\n",
        "\n",
        "      for i in range(1, n_bins):\n",
        "        labels[start_bin + i, class_dict[e[2]] * 3:class_dict[e[2]] * 3 + 3] = [1, 0.0, win_length]\n",
        "\n",
        "      if stop_time_2 > 0.0:\n",
        "        labels[stop_bin, class_dict[e[2]] * 3:class_dict[e[2]] * 3 + 3] = [1, 0.0, stop_time_2]\n",
        "\n",
        "  # divide all time values by window_length\n",
        "  for labelIndex in range(len(labels)):\n",
        "    for valIndex in range(len(labels[labelIndex])):\n",
        "      if valIndex % 3 != 0:\n",
        "        labels[labelIndex][valIndex] /= win_length\n",
        "\n",
        "  return labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eh8YoqFVNhVf"
      },
      "outputs": [],
      "source": [
        "CLASS_ENCODING = {\"car\": 0, \"aircraft\": 1, \"crowds\":2, \"footsteps\":3, \"clocks\":4, \"rainforest\": 5}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWXK4awdQmx8"
      },
      "source": [
        "# Construct Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mLnGwjXvm_P"
      },
      "outputs": [],
      "source": [
        "def construct_data_set(fold_files, path):\n",
        "  shutil.rmtree(path, ignore_errors=True)\n",
        "  os.mkdir(path)\n",
        "\n",
        "  window_length = 2.56\n",
        "  hop_length = 1.0\n",
        "  a_examples_train = []\n",
        "  a_labels_train = []\n",
        "\n",
        "\n",
        "  for i, audio in enumerate(fold_files):\n",
        "    # get \n",
        "    a, window_ranges = construct_examples(audio,win_len=window_length, hop_len=hop_length)\n",
        "    a_examples_train += a\n",
        "\n",
        "    for w in window_ranges:\n",
        "      labels_t = construct_labels(audio.replace(\".wav\", \".txt\").replace('outputs-mono', 'outputs'), w[0], w[1], win_len=window_length)\n",
        "      ll = get_universal_labels(labels_t, CLASS_ENCODING, ex_length=window_length, no_of_div = 9)\n",
        "      a_labels_train.append(ll)\n",
        "  return a_examples_train, a_labels_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUBSH4RDQ6_G"
      },
      "outputs": [],
      "source": [
        "examples_train, labels_train = construct_data_set(fold1_train_files, '/content/train-data')\n",
        "examples_val, labels_val = construct_data_set(fold1_val_files, '/content/val-data')\n",
        "examples_test, labels_test = construct_data_set(fold1_test_files, '/content/test-data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ru11Of8RMzq"
      },
      "source": [
        "# Extract MelSpectrogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "id": "Tz6t6EslAhsJ"
      },
      "outputs": [],
      "source": [
        "def get_log_melspectrogram(audio, sr = 44100, hop_length = 441, win_length = 1764, n_fft = 2048, n_mels = 128, fmin = 0, fmax = 22050):\n",
        "    \"\"\"Return the log-scaled Mel bands of an audio signal.\"\"\"\n",
        "    audio_2 = librosa.util.normalize(audio)\n",
        "    bands = librosa.feature.melspectrogram(\n",
        "        y=audio_2, sr=sr, hop_length=hop_length, win_length = win_length, n_fft=n_fft, n_mels=n_mels)\n",
        "    return librosa.core.power_to_db(bands)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {
        "id": "-mSPzyS1-Q9-"
      },
      "outputs": [],
      "source": [
        "# save melspectrograms for entire set\n",
        "def save_example_mel(example_set, save_path):\n",
        "  for i, audio in enumerate(example_set):\n",
        "    M = get_log_melspectrogram(audio).T\n",
        "    # print(M.shape)\n",
        "    np.save(save_path + str(i) + \".npy\", M)\n",
        "\n",
        "# save labels in numpy format\n",
        "def save_labels_np(label_set, save_path):\n",
        "  for i, audio in enumerate(label_set):\n",
        "    np.save(save_path + str(i) + \".npy\", audio)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "id": "9R7pthk1-jjJ"
      },
      "outputs": [],
      "source": [
        "# save dataset for all train set\n",
        "train_path_ex = '/content/train-data/ex-'\n",
        "train_path_labels = '/content/train-data/label-'\n",
        "val_path_ex = '/content/val-data/ex-'\n",
        "val_path_labels = '/content/val-data/label-'\n",
        "test_path_ex = '/content/test-data/ex-'\n",
        "test_path_labels = '/content/test-data/label-'\n",
        "\n",
        "\n",
        "\n",
        "save_example_mel(examples_train, train_path_ex)\n",
        "save_labels_np(labels_train, train_path_labels)\n",
        "save_example_mel(examples_val, val_path_ex)\n",
        "save_labels_np(labels_val, val_path_labels)\n",
        "save_example_mel(examples_test, test_path_ex)\n",
        "save_labels_np(labels_test, test_path_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvOuMznFRd09"
      },
      "source": [
        "# Sort and Partition Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {
        "id": "uvMbxJLj9x5n"
      },
      "outputs": [],
      "source": [
        "def intOrVal(s):\n",
        "    try:\n",
        "        return int(s)\n",
        "    except ValueError:\n",
        "        return s\n",
        "    \n",
        "def alphanum_key(init_string):\n",
        "    \"\"\" Turn a string into a list of string and number chunks.\n",
        "        \"z23a\" -> [\"z\", 23, \"a\"]\n",
        "    \"\"\"\n",
        "    return [intOrVal(c) for c in re.split('([0-9]+)', init_string)]\n",
        "\n",
        "def sort_nicely(l):\n",
        "    \"\"\" Sort the given list in the way that humans expect.\n",
        "    \"\"\"\n",
        "    l.sort(key=alphanum_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {
        "id": "fjtncXqB91qu"
      },
      "outputs": [],
      "source": [
        "def get_sorted_data(regex_path):\n",
        "  data = glob.glob(regex_path) \n",
        "  sort_nicely(data)\n",
        "  return data\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Load the individual numpy arrays into partition\n",
        "\"\"\"\n",
        "train_data_examples_regex_path = \"/content/train-data/ex-*.npy\"\n",
        "train_data_labels_regex_path = \"/content/train-data/label-*.npy\"\n",
        "val_data_examples_regex_path = \"/content/val-data/ex-*.npy\"\n",
        "val_data_labels_regex_path = \"/content/val-data/label-*.npy\"\n",
        "test_data_examples_regex_path = \"/content/test-data/ex-*.npy\"\n",
        "test_data_labels_regex_path = \"/content/test-data/label-*.npy\"\n",
        "\n",
        "train_data = get_sorted_data(train_data_examples_regex_path)\n",
        "train_labels = get_sorted_data(train_data_labels_regex_path)\n",
        "\n",
        "val_data = get_sorted_data(val_data_examples_regex_path)\n",
        "val_labels = get_sorted_data(val_data_labels_regex_path)\n",
        "\n",
        "test_data = get_sorted_data(test_data_examples_regex_path)\n",
        "test_labels = get_sorted_data(test_data_labels_regex_path)\n",
        "\n",
        "training_examples = [(train_data[i], train_labels[i]) for i in range(len(train_data))]\n",
        "validation_examples = [(val_data[i], val_labels[i]) for i in range(len(val_data))]\n",
        "test_examples = [(test_data[i], test_labels[i]) for i in range(len(test_data))]\n",
        "\n",
        "# shuffle all examples\n",
        "random.seed(7)\n",
        "random.shuffle(training_examples)\n",
        "random.shuffle(validation_examples)\n",
        "random.shuffle(test_examples)\n",
        "partition = {}\n",
        "partition['train'] = training_examples\n",
        "partition['validation'] = validation_examples\n",
        "partition['test'] = test_examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJfMrLr0Tuxg"
      },
      "source": [
        "# Setup Data Generators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {
        "id": "-I5anQDD4b9b"
      },
      "outputs": [],
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, list_examples, batch_size=128, shuffle=True):\n",
        "        # dim\n",
        "        # self.dim = (1,)\n",
        "        self.batch_size = batch_size\n",
        "        self.list_examples = list_examples\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "        # initial shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_examples) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.list_examples[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X, Y = self.generate_data(list_IDs_temp)\n",
        "\n",
        "        return X, Y\n",
        "        \n",
        "    def on_epoch_end(self):\n",
        "      self.indexes = np.arange(len(self.list_examples))\n",
        "\n",
        "      # shuffle indexes at end of epoch\n",
        "      if self.shuffle == True:\n",
        "          np.random.shuffle(self.indexes)\n",
        "\n",
        "    def generate_data(self, list_IDs_temp):\n",
        "        # 'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        X = np.empty([self.batch_size, 257, 128, 1], dtype=np.float64)\n",
        "        Y = np.empty([self.batch_size, 9, 18], dtype=np.float64)\n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "          # Store sample\n",
        "          # load npy array\n",
        "          np_x = np.load(ID[0])\n",
        "\n",
        "          X[i, :, :, 0] = np_x\n",
        "\n",
        "          # load class label\n",
        "          np_y = np.load(ID[1])\n",
        "          Y[i, :, :] = np_y\n",
        "\n",
        "        tau = X.shape[1]          \n",
        "        v = X.shape[2]\n",
        "\n",
        "        # frequency and time masking of X values\n",
        "        warped_frequency_spectrogram = spec_augment_tensorflow.frequency_masking(X, v=v,  frequency_masking_para=8, frequency_mask_num=1)\n",
        "        warped_frequency_time_spectrogram = spec_augment_tensorflow.time_masking(warped_frequency_spectrogram, tau=tau, time_masking_para=25, time_mask_num=2)\n",
        "\n",
        "        X = warped_frequency_time_spectrogram\n",
        "\n",
        "        return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {
        "id": "ylXiTH1Q_0vY"
      },
      "outputs": [],
      "source": [
        "# Parametersa\n",
        "params = {'batch_size': 64, 'shuffle': True}\n",
        "\n",
        "training_generator = DataGenerator(partition['train'], **params)\n",
        "validation_generator = DataGenerator(partition['validation'], **params)\n",
        "test_generator = DataGenerator(partition['test'], **params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wp6_rpxJ-5FA"
      },
      "source": [
        "# Define the YOHO network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {
        "id": "kAHsOD5v-6no"
      },
      "outputs": [],
      "source": [
        "def square_difference_loss(y_true, y_pred):\n",
        "  squared_difference = tf.square(y_true - y_pred)\n",
        "\n",
        "  ss_True = squared_difference[:, :, 0] * 0 + 1 \n",
        "  # ss_True is batchsize, window_len of 1s\n",
        "\n",
        "  # get every 3 value of y_true\n",
        "  ss_0 = y_true[:, :, 0]\n",
        "  ss_1 = y_true[:, :, 3]\n",
        "  ss_2 = y_true[:, :, 6]\n",
        "  ss_3 = y_true[:, :, 9]\n",
        "  ss_4 = y_true[:, :, 12]\n",
        "  ss_5 = y_true[:, :, 15]\n",
        "  # labels across all batch sizes\n",
        "\n",
        "  # stack values\n",
        "  stacked_ss = tf.stack((ss_True, ss_0, ss_0,\n",
        "                         ss_True, ss_1, ss_1,\n",
        "                         ss_True, ss_2, ss_2,\n",
        "                         ss_True, ss_3, ss_3,\n",
        "                         ss_True, ss_4, ss_4,\n",
        "                         ss_True, ss_5, ss_5), axis = 2)\n",
        "  \n",
        "  squared_difference =  tf.multiply(squared_difference, stacked_ss)\n",
        "\n",
        "  return tf.reduce_sum(squared_difference, axis=[-1, -2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {
        "id": "c6sEYWpa2zKd"
      },
      "outputs": [],
      "source": [
        "# Creates mel spctrograms for validation fold for training\n",
        "def create_val_melspectrograms():\n",
        "  win_length = 2.56\n",
        "  hop_size = 1.96\n",
        "  mss_ins = []\n",
        "  win_ranges_list = []\n",
        "\n",
        "\n",
        "  for ii, audio in enumerate(fold1_val_files): # why val?\n",
        "    a, win_ranges = construct_examples(audio, win_len=win_length,hop_len=hop_size)\n",
        "\n",
        "    mss_in = np.zeros((len(a), 257, 128))\n",
        "\n",
        "    preds = np.zeros((len(a), 9, 18))\n",
        "\n",
        "    for i in range(len(a)):\n",
        "      M = get_log_melspectrogram(a[i])\n",
        "      mss_in[i, :, :] = M.T\n",
        "    mss_ins.append(mss_in)\n",
        "    win_ranges_list.append(win_ranges)\n",
        "  return mss_ins,win_ranges_list\n",
        "\n",
        "\n",
        "BASE_MSS_INS, BASE_WIN_RANGE = create_val_melspectrograms()\n",
        "\n",
        "def mk_preds_YOHO_mel(model, ind, window_range_list=BASE_WIN_RANGE, mss_ins=BASE_MSS_INS, no_of_div = 9, hop_size = 1.96, discard = 0.3, win_length = 2.56, max_event_silence = 0.3, sampling_rate = 44100):\n",
        "  preds = model.predict(mss_ins[ind])\n",
        "  events = []\n",
        "\n",
        "  for i in range(len(preds)):\n",
        "    p = preds[i, :, :]\n",
        "    events_curr = []\n",
        "    win_width = win_length / no_of_div\n",
        "    for predIdx in range(len(p)):\n",
        "      for classIdx in range(0, 6):\n",
        "        if p[predIdx][classIdx*3] >= 0.5:\n",
        "          start = win_width * predIdx + win_width * p[predIdx][classIdx*3+1] + window_range_list[ind][i][0]\n",
        "          end = p[predIdx][classIdx*3+2] * win_width + start\n",
        "          events_curr.append([start, end, rev_class_list[classIdx]])\n",
        "\n",
        "    events += events_curr\n",
        "\n",
        "\n",
        "  class_set = set([c[2] for c in events])\n",
        "  class_wise_events = {}\n",
        "\n",
        "  for c in list(class_set):\n",
        "    class_wise_events[c] = []\n",
        "\n",
        "\n",
        "  for c in events:\n",
        "    class_wise_events[c[2]].append(c)\n",
        "    \n",
        "  \n",
        "  all_events = []\n",
        "\n",
        "  for k in list(class_wise_events.keys()):\n",
        "    curr_events = class_wise_events[k]\n",
        "    count = 0\n",
        "\n",
        "    while count < len(curr_events) - 1:\n",
        "      if (curr_events[count][1] >= curr_events[count + 1][0]) or (curr_events[count + 1][0] - curr_events[count][1] <= max_event_silence):\n",
        "        curr_events[count][1] = max(curr_events[count + 1][1], curr_events[count][1])\n",
        "        del curr_events[count + 1]\n",
        "      else:\n",
        "        count += 1\n",
        "\n",
        "    all_events += curr_events\n",
        "\n",
        "  for i in range(len(all_events)):\n",
        "    all_events[i][0] = round(all_events[i][0], 3)\n",
        "    all_events[i][1] = round(all_events[i][1], 3)\n",
        "\n",
        "  all_events.sort(key=lambda x: x[0])\n",
        "\n",
        "  return all_events\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 268,
      "metadata": {
        "id": "RF3BfLy9Rt0Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab7d995c-91c2-4f82-fa70-ca29ffe1b634"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['car', 'aircraft', 'crowds', 'footsteps', 'clocks', 'rainforest']\n"
          ]
        }
      ],
      "source": [
        "rev_class_list = list(CLASS_ENCODING.keys())\n",
        "print(rev_class_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {
        "id": "xteY8W6XlaR_"
      },
      "outputs": [],
      "source": [
        "def frames_to_time(f, sr = 44100.0, hop_size = 441):\n",
        "  return f * hop_size / sr\n",
        "\n",
        "def preds_to_se(p, win_start, audio_clip_length = 2.56):\n",
        "  start_dicts = [-100, -100, -100, -100, -100, -100]\n",
        "  stop_dicts = [-100, -100, -100, -100, -100, -100]\n",
        "\n",
        "\n",
        "  start_speech = -100\n",
        "  start_music = -100\n",
        "  stop_speech = -100\n",
        "  stop_music = -100\n",
        "\n",
        "  audio_events = []\n",
        "\n",
        "  n_frames = p.shape[0]\n",
        "\n",
        "  for j in range(p.shape[1]):\n",
        "    if p[0, j] >= 0.5:\n",
        "      start_dicts[j] = 0\n",
        "\n",
        "  for j in range(p.shape[1]):\n",
        "    for i in range(n_frames - 1):\n",
        "      if p[i, j] < 0.5 and p[i+1, j] >= 0.5:\n",
        "        start_dicts[j] = i+1\n",
        "\n",
        "      elif p[i, j] >= 0.5 and p[i + 1, j] < 0.5:\n",
        "        stop_dicts[j] = i\n",
        "        start_time = frames_to_time(start_dicts[j])\n",
        "        stop_time = frames_to_time(stop_dicts[j])\n",
        "\n",
        "        audio_events.append([start_time+win_start, stop_time+win_start, rev_class_list[j]])\n",
        "        start_dicts[j] = -100\n",
        "        stop_dicts[j] = -100\n",
        "\n",
        "    if start_dicts[j] != -100:\n",
        "      start_time = frames_to_time(start_dicts[j])\n",
        "      stop_time = audio_clip_length\n",
        "      audio_events.append([start_time+win_start, stop_time+win_start, rev_class_list[j]])\n",
        "      start_dicts[j] = -100\n",
        "      stop_dicts[j] = -100\n",
        "\n",
        "  audio_events.sort(key = lambda x: x[0]) \n",
        "  return audio_events"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "metadata": {
        "id": "-lhO-or3cxJm"
      },
      "outputs": [],
      "source": [
        "def extract_eval_labels_2(annotation_path):\n",
        "  events = convert_annotations_to_events(annotation_path)\n",
        "\n",
        "  ann = [[float(e[0]), float(e[1]), e[2]] for e in events]\n",
        "  \n",
        "  n_label = \"/content/eval-files-2/\" + os.path.basename(annotation_path)\n",
        "\n",
        "  with open(n_label, 'w') as fp:\n",
        "    fp.write('\\n'.join('{},{},{}'.format(round(x[0], 5), round(x[1], 5), x[2]) for x in ann))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 271,
      "metadata": {
        "id": "i2pIA6vCcxJm"
      },
      "outputs": [],
      "source": [
        "shutil.rmtree('/content/eval-files-2/', ignore_errors=True)\n",
        "os.mkdir(\"/content/eval-files-2/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {
        "id": "HTXX7tItcxJn"
      },
      "outputs": [],
      "source": [
        "for audio in fold1_val_files:\n",
        "  extract_eval_labels_2(audio.replace(\".wav\", \".txt\").replace(\"outputs-mono\", \"outputs\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "\n",
        "import wandb\n",
        "wandb.login(key=\"81a76bf7b4c360aaed690ff2b0d01f019725e53f\")\n",
        "run = wandb.init(\n",
        "    name = \"YOHOArch - MelBandsChange\", ## Wandb creates random run names if you skip this field\n",
        "    reinit = True, ### Allows reinitalizing runs when you re-run this cell\n",
        "    # run_id = ### Insert specific run id here if you want to resume a previous run\n",
        "    # resume = \"must\" ### You need this to resume previous runs, but comment out reinit = True when using this\n",
        "    project = \"idl-project\", ### Project should be created in your wandb account \n",
        "    config = {\n",
        "        'lr': 1e-3,\n",
        "        'architecture': 'YOHO-MelBandsChange',\n",
        "        \n",
        "    } ### Wandb Config for your run\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 908,
          "referenced_widgets": [
            "d86553659a904b3aa3f8a16e1bc9309e",
            "2844f9b545184ae4857293bee5a31052",
            "c1d70626f56c4ef291d1322ee86e1a3c",
            "71f6ebf10eac41abb093e05fa07fbfdf",
            "a0766ee9e6024542b4a4fd76130ff0e7",
            "b3124f87e101407b8fa4fe77b93ca84a",
            "b1271aa0be754075b10daa109e3e5605",
            "a23928937eaf4a10b731d26b02d3880e"
          ]
        },
        "id": "tC2A9LCHVZHf",
        "outputId": "183c4fea-3917-4b15-f3ae-e509f7d3ba34"
      },
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.9/dist-packages (0.15.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.21.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (8.1.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.1.31)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.9/dist-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb) (67.6.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (5.9.4)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.9/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:6lo0oq4m) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='30.691 MB of 30.691 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d86553659a904b3aa3f8a16e1bc9309e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>curr_error</td><td>█▇▃▃▃▂▂▂▃▂▂▂▂▂▃▂▂▂▂▁▁▂▁▂▂▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>f_measure</td><td> ▁▆▆▆▇▇▇▆▇▇▇▇▇▇█▇▇▇██▇█▇▇██▇███▇████████</td></tr><tr><td>training_loss</td><td>█▅▄▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>█▅▄▃▃▂▂▂▂▂▂▂▂▁▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>curr_error</td><td>0.18987</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>f_measure</td><td>0.87751</td></tr><tr><td>training_loss</td><td>3.67912</td></tr><tr><td>validation_loss</td><td>3.96756</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">YOHOArch - Baseline100</strong> at: <a href='https://wandb.ai/eshetty-11785/idl-project/runs/6lo0oq4m' target=\"_blank\">https://wandb.ai/eshetty-11785/idl-project/runs/6lo0oq4m</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230427_194143-6lo0oq4m/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:6lo0oq4m). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230427_213429-8cd04l2c</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/eshetty-11785/idl-project/runs/8cd04l2c' target=\"_blank\">YOHOArch - MelBandsChange</a></strong> to <a href='https://wandb.ai/eshetty-11785/idl-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/eshetty-11785/idl-project' target=\"_blank\">https://wandb.ai/eshetty-11785/idl-project</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/eshetty-11785/idl-project/runs/8cd04l2c' target=\"_blank\">https://wandb.ai/eshetty-11785/idl-project/runs/8cd04l2c</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5xYUUItOV3At"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7xQxmcmNUi6"
      },
      "source": [
        "# Train Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {
        "id": "i9RIHH_49zOE"
      },
      "outputs": [],
      "source": [
        "class KerasFinalCallback(tf.keras.callbacks.Callback):\n",
        "  def __init__(self):\n",
        "    super(KerasFinalCallback, self).__init__()\n",
        "    self.best_f1 = 0.0\n",
        "    self.best_error = np.inf\n",
        "    \n",
        "  def on_train_begin(self, logs=None):\n",
        "    pass\n",
        "\n",
        "  def on_train_end(self, logs=None):\n",
        "    pass\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    if epoch > 1:\n",
        "      for ii, audio in enumerate(fold1_val_files):\n",
        "        audio_file_path = audio\n",
        "        see = mk_preds_YOHO_mel(self.model, ii)\n",
        "        n_label = \"/content/eval-files-2/\" + os.path.basename(audio_file_path).replace(\".wav\" ,\"\") + \"-se-prediction.txt\"\n",
        "\n",
        "        with open(n_label, 'w') as fp:\n",
        "          fp.write('\\n'.join('{},{},{}'.format(round(x[0], 5), round(x[1], 5), x[2]) for x in see))\n",
        "\n",
        "      destination = \"/content/eval-files-2/\"\n",
        "      test_set = glob.glob(destination + \"*[0-9].txt\")\n",
        "\n",
        "      eval_path = \"/content/\"\n",
        "\n",
        "\n",
        "      file_list = [\n",
        "          {\n",
        "          'reference_file': tt,\n",
        "          'estimated_file': tt.replace(\".txt\",\"-se-prediction.txt\")\n",
        "          }\n",
        "          for tt in test_set\n",
        "      ]\n",
        "\n",
        "      data = []\n",
        "\n",
        "      # Get used event labels\n",
        "      all_data = dcase_util.containers.MetaDataContainer()\n",
        "      for file_pair in file_list:\n",
        "          reference_event_list = sed_eval.io.load_event_list(\n",
        "              filename=file_pair['reference_file']\n",
        "          )\n",
        "          estimated_event_list = sed_eval.io.load_event_list(\n",
        "              filename=file_pair['estimated_file']\n",
        "          )\n",
        "\n",
        "          data.append({'reference_event_list': reference_event_list,\n",
        "                      'estimated_event_list': estimated_event_list})\n",
        "\n",
        "          all_data += reference_event_list\n",
        "\n",
        "      event_labels = all_data.unique_event_labels\n",
        "\n",
        "      # Start evaluating\n",
        "\n",
        "      # Create metrics classes, define parameters\n",
        "      segment_based_metrics = sed_eval.sound_event.SegmentBasedMetrics(\n",
        "          event_label_list=event_labels,\n",
        "          time_resolution=1.0\n",
        "      )\n",
        "\n",
        "      event_based_metrics = sed_eval.sound_event.EventBasedMetrics(\n",
        "          event_label_list=event_labels,\n",
        "          t_collar=1.0\n",
        "      )\n",
        "\n",
        "      # Go through files\n",
        "      for file_pair in data:\n",
        "          segment_based_metrics.evaluate(\n",
        "              reference_event_list=file_pair['reference_event_list'],\n",
        "              estimated_event_list=file_pair['estimated_event_list']\n",
        "          )\n",
        "\n",
        "          event_based_metrics.evaluate(\n",
        "              reference_event_list=file_pair['reference_event_list'],\n",
        "              estimated_event_list=file_pair['estimated_event_list']\n",
        "          )\n",
        "\n",
        "      # Get only certain metrics\n",
        "      overall_segment_based_metrics = segment_based_metrics.results_overall_metrics()\n",
        "      curr_f1 = overall_segment_based_metrics['f_measure']['f_measure']\n",
        "      curr_error = overall_segment_based_metrics['error_rate']['error_rate']\n",
        "\n",
        "      wandb.log({\"f_measure\":curr_f1, 'curr_error': curr_error, 'validation_loss':logs['val_loss'], \n",
        "               'training_loss': logs['loss'], 'epoch': epoch})\n",
        "      print(logs)\n",
        "      if curr_f1 > self.best_f1:\n",
        "        self.best_f1 = curr_f1\n",
        "        self.model.save_weights(\"/content/model-best-f1.h5\")\n",
        "        wandb.save('/content/model-best-f1.h5')\n",
        "\n",
        "\n",
        "      if curr_error < self.best_error:\n",
        "        self.best_error = curr_error\n",
        "        self.model.save_weights(\"/content/model-best-error.h5\")\n",
        "        wandb.save('/content/model-best-error.h5')\n",
        "\n",
        "\n",
        "      print(\"F-measure: {:.3f} vs {:.3f}\".format(curr_f1, self.best_f1))\n",
        "      print(\"Error rate: {:.3f} vs {:.3f}\".format(curr_error, self.best_error))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {
        "id": "ujnpubM3Blr-"
      },
      "outputs": [],
      "source": [
        "class YOHOBlock:\n",
        "  def __init__(self, stride, num_filters, index, input):\n",
        "      X = tf.keras.layers.DepthwiseConv2D(kernel_size=[3,3], strides = stride, depth_multiplier=1, padding='same', use_bias=False,\n",
        "                                      activation=None, name=\"layer\"+ str(index + 2)+\"/depthwise_conv\")(input)\n",
        "      X = tf.keras.layers.BatchNormalization(center=True, scale=False, epsilon=1e-4, name = \"layer\"+ str(index + 2)+\"/depthwise_conv/bn\")(X)\n",
        "      X = tf.keras.layers.ReLU(name=\"layer\"+ str(index + 2)+\"/depthwise_conv/relu\")(X)\n",
        "      X = tf.keras.layers.Conv2D(filters =num_filters, kernel_size=[1, 1], strides=1, padding='same', use_bias=False, activation=None,\n",
        "                                name = \"layer\"+ str(index + 2)+\"/pointwise_conv\",\n",
        "                                kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(X)\n",
        "      X = tf.keras.layers.BatchNormalization(center=True, scale=False, epsilon=1e-4, name = \"layer\"+ str(index + 2)+\"/pointwise_conv/bn\")(X)\n",
        "      self.output = tf.keras.layers.ReLU(name=\"layer\"+ str(index + 2)+\"/pointwise_conv/relu\")(X)\n",
        "\n",
        "class Network:\n",
        "  def __init__(self) -> None:\n",
        "    self.NETWORK_BLOCK_LAYERS = [\n",
        "      # (stride, num_filters)\n",
        "      (1,   64),\n",
        "      (2,  128),\n",
        "      (1,  128),\n",
        "      (2,  256),\n",
        "      (1,  256),\n",
        "      (2,  512),\n",
        "      (1,  512),\n",
        "      (1,  512),\n",
        "      (1,  512),\n",
        "      (1,  512),\n",
        "      (1,  512),\n",
        "      (2, 1024),\n",
        "      (1, 1024),\n",
        "      (1, 512),\n",
        "      (1, 256),\n",
        "      (1, 128),\n",
        "    ]\n",
        "    self.m_features = tf.keras.Input(shape=(257, 128), name=\"mel_input\")\n",
        "    X = self.m_features\n",
        "    X = tf.keras.layers.Reshape((257, 128, 1))(X)\n",
        "    X = tf.keras.layers.Conv2D(filters = 32, kernel_size=[3, 3], strides=2, padding='same', use_bias=False,\n",
        "                              activation=None, name = \"layer1/conv\",\n",
        "                                kernel_regularizer=l2(1e-3), bias_regularizer=l2(1e-3))(X)\n",
        "    X = tf.keras.layers.BatchNormalization(center=True, scale=False, epsilon=1e-4, name = \"layer1/bn\")(X)\n",
        "    X = tf.keras.layers.ReLU(name=\"layer1/relu\")(X)\n",
        "\n",
        "    X = tf.keras.layers.SpatialDropout2D(0.1)(X)\n",
        "    \n",
        "    for index in range(len(self.NETWORK_BLOCK_LAYERS)):\n",
        "      X = YOHOBlock(stride=self.NETWORK_BLOCK_LAYERS[index][0], num_filters=self.NETWORK_BLOCK_LAYERS[index][1], index=index, input=X).output\n",
        "\n",
        "    _, _, sx, sy = X.shape\n",
        "    X = tf.keras.layers.Reshape((-1, int(sx * sy)))(X)\n",
        "    self.pred = tf.keras.layers.Conv1D(18, kernel_size=1, activation=\"sigmoid\")(X)\n",
        "\n",
        "\n",
        "model_arch = Network()\n",
        "model = tf.keras.Model(\n",
        "      name='YOHO', inputs=model_arch.m_features,outputs=[model_arch.pred])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQsXSvgyBoZM",
        "outputId": "764b2c51-46fe-4739-a119-926055e40dc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"YOHO\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mel_input (InputLayer)      [(None, 257, 128)]        0         \n",
            "                                                                 \n",
            " reshape_31 (Reshape)        (None, 257, 128, 1)       0         \n",
            "                                                                 \n",
            " layer1/conv (Conv2D)        (None, 129, 64, 32)       288       \n",
            "                                                                 \n",
            " layer1/bn (BatchNormalizati  (None, 129, 64, 32)      96        \n",
            " on)                                                             \n",
            "                                                                 \n",
            " layer1/relu (ReLU)          (None, 129, 64, 32)       0         \n",
            "                                                                 \n",
            " spatial_dropout2d_16 (Spati  (None, 129, 64, 32)      0         \n",
            " alDropout2D)                                                    \n",
            "                                                                 \n",
            " layer2/depthwise_conv (Dept  (None, 129, 64, 32)      288       \n",
            " hwiseConv2D)                                                    \n",
            "                                                                 \n",
            " layer2/depthwise_conv/bn (B  (None, 129, 64, 32)      96        \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " layer2/depthwise_conv/relu   (None, 129, 64, 32)      0         \n",
            " (ReLU)                                                          \n",
            "                                                                 \n",
            " layer2/pointwise_conv (Conv  (None, 129, 64, 64)      2048      \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " layer2/pointwise_conv/bn (B  (None, 129, 64, 64)      192       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " layer2/pointwise_conv/relu   (None, 129, 64, 64)      0         \n",
            " (ReLU)                                                          \n",
            "                                                                 \n",
            " layer3/depthwise_conv (Dept  (None, 65, 32, 64)       576       \n",
            " hwiseConv2D)                                                    \n",
            "                                                                 \n",
            " layer3/depthwise_conv/bn (B  (None, 65, 32, 64)       192       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " layer3/depthwise_conv/relu   (None, 65, 32, 64)       0         \n",
            " (ReLU)                                                          \n",
            "                                                                 \n",
            " layer3/pointwise_conv (Conv  (None, 65, 32, 128)      8192      \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " layer3/pointwise_conv/bn (B  (None, 65, 32, 128)      384       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " layer3/pointwise_conv/relu   (None, 65, 32, 128)      0         \n",
            " (ReLU)                                                          \n",
            "                                                                 \n",
            " layer4/depthwise_conv (Dept  (None, 65, 32, 128)      1152      \n",
            " hwiseConv2D)                                                    \n",
            "                                                                 \n",
            " layer4/depthwise_conv/bn (B  (None, 65, 32, 128)      384       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " layer4/depthwise_conv/relu   (None, 65, 32, 128)      0         \n",
            " (ReLU)                                                          \n",
            "                                                                 \n",
            " layer4/pointwise_conv (Conv  (None, 65, 32, 128)      16384     \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " layer4/pointwise_conv/bn (B  (None, 65, 32, 128)      384       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " layer4/pointwise_conv/relu   (None, 65, 32, 128)      0         \n",
            " (ReLU)                                                          \n",
            "                                                                 \n",
            " layer5/depthwise_conv (Dept  (None, 33, 16, 128)      1152      \n",
            " hwiseConv2D)                                                    \n",
            "                                                                 \n",
            " layer5/depthwise_conv/bn (B  (None, 33, 16, 128)      384       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " layer5/depthwise_conv/relu   (None, 33, 16, 128)      0         \n",
            " (ReLU)                                                          \n",
            "                                                                 \n",
            " layer5/pointwise_conv (Conv  (None, 33, 16, 256)      32768     \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " layer5/pointwise_conv/bn (B  (None, 33, 16, 256)      768       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " layer5/pointwise_conv/relu   (None, 33, 16, 256)      0         \n",
            " (ReLU)                                                          \n",
            "                                                                 \n",
            " layer6/depthwise_conv (Dept  (None, 33, 16, 256)      2304      \n",
            " hwiseConv2D)                                                    \n",
            "                                                                 \n",
            " layer6/depthwise_conv/bn (B  (None, 33, 16, 256)      768       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " layer6/depthwise_conv/relu   (None, 33, 16, 256)      0         \n",
            " (ReLU)                                                          \n",
            "                                                                 \n",
            " layer6/pointwise_conv (Conv  (None, 33, 16, 256)      65536     \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " layer6/pointwise_conv/bn (B  (None, 33, 16, 256)      768       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " layer6/pointwise_conv/relu   (None, 33, 16, 256)      0         \n",
            " (ReLU)                                                          \n",
            "                                                                 \n",
            " layer7/depthwise_conv (Dept  (None, 17, 8, 256)       2304      \n",
            " hwiseConv2D)                                                    \n",
            "                                                                 \n",
            " layer7/depthwise_conv/bn (B  (None, 17, 8, 256)       768       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " layer7/depthwise_conv/relu   (None, 17, 8, 256)       0         \n",
            " (ReLU)                                                          \n",
            "                                                                 \n",
            " layer7/pointwise_conv (Conv  (None, 17, 8, 512)       131072    \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " layer7/pointwise_conv/bn (B  (None, 17, 8, 512)       1536      \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " layer7/pointwise_conv/relu   (None, 17, 8, 512)       0         \n",
            " (ReLU)                                                          \n",
            "                                                                 \n",
            " layer8/depthwise_conv (Dept  (None, 17, 8, 512)       4608      \n",
            " hwiseConv2D)                                                    \n",
            "                                                                 \n",
            " layer8/depthwise_conv/bn (B  (None, 17, 8, 512)       1536      \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " layer8/depthwise_conv/relu   (None, 17, 8, 512)       0         \n",
            " (ReLU)                                                          \n",
            "                                                                 \n",
            " layer8/pointwise_conv (Conv  (None, 17, 8, 512)       262144    \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " layer8/pointwise_conv/bn (B  (None, 17, 8, 512)       1536      \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " layer8/pointwise_conv/relu   (None, 17, 8, 512)       0         \n",
            " (ReLU)                                                          \n",
            "                                                                 \n",
            " layer9/depthwise_conv (Dept  (None, 17, 8, 512)       4608      \n",
            " hwiseConv2D)                                                    \n",
            "                                                                 \n",
            " layer9/depthwise_conv/bn (B  (None, 17, 8, 512)       1536      \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " layer9/depthwise_conv/relu   (None, 17, 8, 512)       0         \n",
            " (ReLU)                                                          \n",
            "                                                                 \n",
            " layer9/pointwise_conv (Conv  (None, 17, 8, 512)       262144    \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " layer9/pointwise_conv/bn (B  (None, 17, 8, 512)       1536      \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " layer9/pointwise_conv/relu   (None, 17, 8, 512)       0         \n",
            " (ReLU)                                                          \n",
            "                                                                 \n",
            " layer10/depthwise_conv (Dep  (None, 17, 8, 512)       4608      \n",
            " thwiseConv2D)                                                   \n",
            "                                                                 \n",
            " layer10/depthwise_conv/bn (  (None, 17, 8, 512)       1536      \n",
            " BatchNormalization)                                             \n",
            "                                                                 \n",
            " layer10/depthwise_conv/relu  (None, 17, 8, 512)       0         \n",
            "  (ReLU)                                                         \n",
            "                                                                 \n",
            " layer10/pointwise_conv (Con  (None, 17, 8, 512)       262144    \n",
            " v2D)                                                            \n",
            "                                                                 \n",
            " layer10/pointwise_conv/bn (  (None, 17, 8, 512)       1536      \n",
            " BatchNormalization)                                             \n",
            "                                                                 \n",
            " layer10/pointwise_conv/relu  (None, 17, 8, 512)       0         \n",
            "  (ReLU)                                                         \n",
            "                                                                 \n",
            " layer11/depthwise_conv (Dep  (None, 17, 8, 512)       4608      \n",
            " thwiseConv2D)                                                   \n",
            "                                                                 \n",
            " layer11/depthwise_conv/bn (  (None, 17, 8, 512)       1536      \n",
            " BatchNormalization)                                             \n",
            "                                                                 \n",
            " layer11/depthwise_conv/relu  (None, 17, 8, 512)       0         \n",
            "  (ReLU)                                                         \n",
            "                                                                 \n",
            " layer11/pointwise_conv (Con  (None, 17, 8, 512)       262144    \n",
            " v2D)                                                            \n",
            "                                                                 \n",
            " layer11/pointwise_conv/bn (  (None, 17, 8, 512)       1536      \n",
            " BatchNormalization)                                             \n",
            "                                                                 \n",
            " layer11/pointwise_conv/relu  (None, 17, 8, 512)       0         \n",
            "  (ReLU)                                                         \n",
            "                                                                 \n",
            " layer12/depthwise_conv (Dep  (None, 17, 8, 512)       4608      \n",
            " thwiseConv2D)                                                   \n",
            "                                                                 \n",
            " layer12/depthwise_conv/bn (  (None, 17, 8, 512)       1536      \n",
            " BatchNormalization)                                             \n",
            "                                                                 \n",
            " layer12/depthwise_conv/relu  (None, 17, 8, 512)       0         \n",
            "  (ReLU)                                                         \n",
            "                                                                 \n",
            " layer12/pointwise_conv (Con  (None, 17, 8, 512)       262144    \n",
            " v2D)                                                            \n",
            "                                                                 \n",
            " layer12/pointwise_conv/bn (  (None, 17, 8, 512)       1536      \n",
            " BatchNormalization)                                             \n",
            "                                                                 \n",
            " layer12/pointwise_conv/relu  (None, 17, 8, 512)       0         \n",
            "  (ReLU)                                                         \n",
            "                                                                 \n",
            " layer13/depthwise_conv (Dep  (None, 9, 4, 512)        4608      \n",
            " thwiseConv2D)                                                   \n",
            "                                                                 \n",
            " layer13/depthwise_conv/bn (  (None, 9, 4, 512)        1536      \n",
            " BatchNormalization)                                             \n",
            "                                                                 \n",
            " layer13/depthwise_conv/relu  (None, 9, 4, 512)        0         \n",
            "  (ReLU)                                                         \n",
            "                                                                 \n",
            " layer13/pointwise_conv (Con  (None, 9, 4, 1024)       524288    \n",
            " v2D)                                                            \n",
            "                                                                 \n",
            " layer13/pointwise_conv/bn (  (None, 9, 4, 1024)       3072      \n",
            " BatchNormalization)                                             \n",
            "                                                                 \n",
            " layer13/pointwise_conv/relu  (None, 9, 4, 1024)       0         \n",
            "  (ReLU)                                                         \n",
            "                                                                 \n",
            " layer14/depthwise_conv (Dep  (None, 9, 4, 1024)       9216      \n",
            " thwiseConv2D)                                                   \n",
            "                                                                 \n",
            " layer14/depthwise_conv/bn (  (None, 9, 4, 1024)       3072      \n",
            " BatchNormalization)                                             \n",
            "                                                                 \n",
            " layer14/depthwise_conv/relu  (None, 9, 4, 1024)       0         \n",
            "  (ReLU)                                                         \n",
            "                                                                 \n",
            " layer14/pointwise_conv (Con  (None, 9, 4, 1024)       1048576   \n",
            " v2D)                                                            \n",
            "                                                                 \n",
            " layer14/pointwise_conv/bn (  (None, 9, 4, 1024)       3072      \n",
            " BatchNormalization)                                             \n",
            "                                                                 \n",
            " layer14/pointwise_conv/relu  (None, 9, 4, 1024)       0         \n",
            "  (ReLU)                                                         \n",
            "                                                                 \n",
            " layer15/depthwise_conv (Dep  (None, 9, 4, 1024)       9216      \n",
            " thwiseConv2D)                                                   \n",
            "                                                                 \n",
            " layer15/depthwise_conv/bn (  (None, 9, 4, 1024)       3072      \n",
            " BatchNormalization)                                             \n",
            "                                                                 \n",
            " layer15/depthwise_conv/relu  (None, 9, 4, 1024)       0         \n",
            "  (ReLU)                                                         \n",
            "                                                                 \n",
            " layer15/pointwise_conv (Con  (None, 9, 4, 512)        524288    \n",
            " v2D)                                                            \n",
            "                                                                 \n",
            " layer15/pointwise_conv/bn (  (None, 9, 4, 512)        1536      \n",
            " BatchNormalization)                                             \n",
            "                                                                 \n",
            " layer15/pointwise_conv/relu  (None, 9, 4, 512)        0         \n",
            "  (ReLU)                                                         \n",
            "                                                                 \n",
            " layer16/depthwise_conv (Dep  (None, 9, 4, 512)        4608      \n",
            " thwiseConv2D)                                                   \n",
            "                                                                 \n",
            " layer16/depthwise_conv/bn (  (None, 9, 4, 512)        1536      \n",
            " BatchNormalization)                                             \n",
            "                                                                 \n",
            " layer16/depthwise_conv/relu  (None, 9, 4, 512)        0         \n",
            "  (ReLU)                                                         \n",
            "                                                                 \n",
            " layer16/pointwise_conv (Con  (None, 9, 4, 256)        131072    \n",
            " v2D)                                                            \n",
            "                                                                 \n",
            " layer16/pointwise_conv/bn (  (None, 9, 4, 256)        768       \n",
            " BatchNormalization)                                             \n",
            "                                                                 \n",
            " layer16/pointwise_conv/relu  (None, 9, 4, 256)        0         \n",
            "  (ReLU)                                                         \n",
            "                                                                 \n",
            " layer17/depthwise_conv (Dep  (None, 9, 4, 256)        2304      \n",
            " thwiseConv2D)                                                   \n",
            "                                                                 \n",
            " layer17/depthwise_conv/bn (  (None, 9, 4, 256)        768       \n",
            " BatchNormalization)                                             \n",
            "                                                                 \n",
            " layer17/depthwise_conv/relu  (None, 9, 4, 256)        0         \n",
            "  (ReLU)                                                         \n",
            "                                                                 \n",
            " layer17/pointwise_conv (Con  (None, 9, 4, 128)        32768     \n",
            " v2D)                                                            \n",
            "                                                                 \n",
            " layer17/pointwise_conv/bn (  (None, 9, 4, 128)        384       \n",
            " BatchNormalization)                                             \n",
            "                                                                 \n",
            " layer17/pointwise_conv/relu  (None, 9, 4, 128)        0         \n",
            "  (ReLU)                                                         \n",
            "                                                                 \n",
            " reshape_32 (Reshape)        (None, 9, 512)            0         \n",
            "                                                                 \n",
            " conv1d_15 (Conv1D)          (None, 9, 18)             9234      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,938,898\n",
            "Trainable params: 3,911,634\n",
            "Non-trainable params: 27,264\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {
        "id": "hSJFYjO4BqBQ"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), \n",
        "              loss=square_difference_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FQFJ5yiB1OY",
        "outputId": "8df6b4b6-8f0e-4ef5-b6c0-dd5ca592920f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            " 6/76 [=>............................] - ETA: 14s - loss: 41.0422"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1058s vs `on_train_batch_end` time: 0.1122s). Check your callbacks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 17s 224ms/step - loss: 36.8114 - val_loss: 37.1529\n",
            "Epoch 2/300\n",
            "76/76 [==============================] - 17s 224ms/step - loss: 29.9352 - val_loss: 31.6818\n",
            "Epoch 3/300\n",
            "2/2 [==============================] - 1s 254ms/step\n",
            "2/2 [==============================] - 0s 265ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 289ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 270ms/step\n",
            "2/2 [==============================] - 0s 295ms/step\n",
            "2/2 [==============================] - 0s 278ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 376ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 0s 257ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "{'loss': 25.173168182373047, 'val_loss': 27.666597366333008}\n",
            "F-measure: nan vs 0.000\n",
            "Error rate: 1.000 vs 1.000\n",
            "76/76 [==============================] - 22s 292ms/step - loss: 25.1732 - val_loss: 27.6666\n",
            "Epoch 4/300\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 15ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "{'loss': 21.66702651977539, 'val_loss': 24.51617431640625}\n",
            "F-measure: nan vs 0.000\n",
            "Error rate: 1.000 vs 1.000\n",
            "76/76 [==============================] - 19s 254ms/step - loss: 21.6670 - val_loss: 24.5162\n",
            "Epoch 5/300\n",
            "60/76 [======================>.......] - ETA: 3s - loss: 19.2846"
          ]
        }
      ],
      "source": [
        "model.fit(training_generator, validation_data=validation_generator, epochs=300, callbacks=[KerasFinalCallback()], verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run.finish()\n",
        "test_loss = model.evaluate(test_generator)\n",
        "print('test_loss:', test_loss)"
      ],
      "metadata": {
        "id": "xfWjFws27UM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference\n"
      ],
      "metadata": {
        "id": "Tj0i6hmMvhjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mel_spectrograms(audio_file):\n",
        "  win_length = 2.56\n",
        "  hop_size = 1.96\n",
        "\n",
        "  a, win_ranges = construct_examples(audio_file, win_len=win_length,hop_len=hop_size)\n",
        "\n",
        "  mss_in = np.zeros((len(a), 257, 128))\n",
        "\n",
        "  preds = np.zeros((len(a), 9, 18))\n",
        "\n",
        "  for i in range(len(a)):\n",
        "    M = get_log_melspectrogram(a[i])\n",
        "    mss_in[i, :, :] = M.T\n",
        "\n",
        "  return mss_in,win_ranges\n",
        "\n",
        "\n",
        "def run_inference(model, win_ranges, mss_in, no_of_div = 9, hop_size = 1.96, discard = 0.3, win_length = 2.56, max_event_silence = 0.3, sampling_rate = 44100):\n",
        "  preds = model.predict(mss_in)\n",
        "  events = []\n",
        "\n",
        "  for i in range(len(preds)):\n",
        "    p = preds[i, :, :]\n",
        "    events_curr = []\n",
        "    win_width = win_length / no_of_div\n",
        "    for predIdx in range(len(p)):\n",
        "      for classIdx in range(0, 6):\n",
        "        if p[predIdx][classIdx*3] >= 0.5:\n",
        "          start = win_width * predIdx + win_width * p[predIdx][classIdx*3+1] + win_ranges[i][0]\n",
        "          end = p[predIdx][classIdx*3+2] * win_width + start\n",
        "          events_curr.append([start, end, rev_class_list[classIdx]])\n",
        "\n",
        "    events += events_curr\n",
        "\n",
        "\n",
        "  class_set = set([c[2] for c in events])\n",
        "  class_wise_events = {}\n",
        "\n",
        "  for c in list(class_set):\n",
        "    class_wise_events[c] = []\n",
        "\n",
        "\n",
        "  for c in events:\n",
        "    class_wise_events[c[2]].append(c)\n",
        "    \n",
        "  \n",
        "  all_events = []\n",
        "\n",
        "  for k in list(class_wise_events.keys()):\n",
        "    curr_events = class_wise_events[k]\n",
        "    count = 0\n",
        "\n",
        "    while count < len(curr_events) - 1:\n",
        "      if (curr_events[count][1] >= curr_events[count + 1][0]) or (curr_events[count + 1][0] - curr_events[count][1] <= max_event_silence):\n",
        "        curr_events[count][1] = max(curr_events[count + 1][1], curr_events[count][1])\n",
        "        del curr_events[count + 1]\n",
        "      else:\n",
        "        count += 1\n",
        "\n",
        "    all_events += curr_events\n",
        "\n",
        "  for i in range(len(all_events)):\n",
        "    all_events[i][0] = round(all_events[i][0], 3)\n",
        "    all_events[i][1] = round(all_events[i][1], 3)\n",
        "\n",
        "  all_events.sort(key=lambda x: x[0])\n",
        "\n",
        "  return all_events\n"
      ],
      "metadata": {
        "id": "j6CN3GsuvkTS"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def infer_events(model, audio_file):\n",
        "\n",
        "  # create a temp file with single channel of the audio\n",
        "  temp_file = audio_file.replace(\"test\", \"test-mono\")\n",
        "  command = command = \"sox \" + audio_file + \" \" + temp_file + \" channels 1\"\n",
        "  p = Popen(command, stdin=PIPE, stdout=PIPE, stderr=PIPE, shell=True)\n",
        "  output, err = p.communicate()\n",
        "\n",
        "  # make the audio into the melspectrograms\n",
        "  mss_in, win_ranges = create_mel_spectrograms(temp_file)\n",
        "\n",
        "\n",
        "  # run inference to generate the set of events\n",
        "  events = run_inference(model, win_ranges, mss_in)\n",
        "  output_file = \"test-crowds.txt\"\n",
        "\n",
        "\n",
        "  with open(output_file, 'w') as fp:\n",
        "    fp.write('\\n'.join('{},{},{}'.format(round(x[0], 5), round(x[1], 5), x[2]) for x in events))\n",
        "\n",
        "infer_events(model, '/content/test-car.wav')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkP-EWfSwsFO",
        "outputId": "14703885-1696-4be1-a677-9168440c5ea7"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/test-mono-car.wav\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "[[0.008, 8.44, 'car'], [8.48, 8.755, 'footsteps']]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d86553659a904b3aa3f8a16e1bc9309e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2844f9b545184ae4857293bee5a31052",
              "IPY_MODEL_c1d70626f56c4ef291d1322ee86e1a3c"
            ],
            "layout": "IPY_MODEL_71f6ebf10eac41abb093e05fa07fbfdf"
          }
        },
        "2844f9b545184ae4857293bee5a31052": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0766ee9e6024542b4a4fd76130ff0e7",
            "placeholder": "​",
            "style": "IPY_MODEL_b3124f87e101407b8fa4fe77b93ca84a",
            "value": "30.691 MB of 30.746 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "c1d70626f56c4ef291d1322ee86e1a3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1271aa0be754075b10daa109e3e5605",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a23928937eaf4a10b731d26b02d3880e",
            "value": 0.9981968970885496
          }
        },
        "71f6ebf10eac41abb093e05fa07fbfdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0766ee9e6024542b4a4fd76130ff0e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3124f87e101407b8fa4fe77b93ca84a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1271aa0be754075b10daa109e3e5605": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a23928937eaf4a10b731d26b02d3880e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}